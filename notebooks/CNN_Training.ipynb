{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade jax jaxlib\n",
    "#!pip install git+https://github.com/deepmind/dm-haiku\n",
    "#!pip install optax\n",
    "!pip install --quiet --upgrade objax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"paths = glob.glob('images/*/*.jpg')\n",
    "paths = rd.sample(paths, len(paths))\n",
    "\n",
    "image_paths = tf.convert_to_tensor(paths, dtype=tf.string)\n",
    "labels = tf.convert_to_tensor([int(i.split('/')[2]) for i in paths])\n",
    "\n",
    "train_image_paths, train_labels = image_paths[0:110], labels[0:110]\n",
    "test_image_paths, test_labels = image_paths[110:141], labels[110:141]\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_image_paths, test_labels))\n",
    "\n",
    "def load_fn(path, label):\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(path))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    \n",
    "    image = image * (2. / 255) - 1\n",
    "    \n",
    "    image = tf.image.resize(image, size=[224, 224])\n",
    "    image = tf.transpose(image, (2, 1, 0))\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "train_ds = train_dataset.map(load_fn, num_parallel_calls = 2).batch(10)\n",
    "test_ds = test_dataset.map(load_fn, num_parallel_calls = 2).batch(1)\"\"\"\n",
    "\n",
    "\"\"\"Tests for Data Loading\"\"\"\n",
    "# Ensuring images aren't repeated xD\n",
    "#count = 0 \n",
    "#prev_next_elem = tf.ones((32, 224, 224, 3))\n",
    "#for next_element in ds:\n",
    "#    count += 1\n",
    "#    print(next_element[0].shape)\n",
    "    #print(prev_next_elem.shape)\n",
    "    #print(f\"Pass {count}\")\n",
    "    #print(next_element[0] == prev_next_elem)\n",
    "    #prev_next_elem = next_element[0]\n",
    "    \n",
    "\"\"\"for epoch in range(20):\n",
    "    count = 0\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for next_element in train_ds:\n",
    "        count = count+len(next_element[0])\n",
    "        print(f\"Processed: {count} Images\")\n",
    "        loss = train_op(next_element[0].numpy(), next_element[1].numpy())[0]\n",
    "        print(f\"Loss is :{loss}\")\n",
    "        print(\"===\" * 10)\n",
    "    accuracy = 0        \n",
    "    if epoch % 4 == 0:\n",
    "        for next_element in test_ds:\n",
    "            p = eval_op(next_element[0].numpy())\n",
    "            accuracy += (np.argmax(p, axis=1) == next_element[1].numpy()).sum()\n",
    "        print(\"***\" * 10)\n",
    "        print(f\"Accuracy: {accuracy / len(test_ds)}\")\n",
    "        print(\"***\" * 10)  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "####### PYTORCH\n",
    "\n",
    "\n",
    "\"\"\"class CustomJAXDataset(Dataset):\n",
    "    def __init__(self, path_to_data, labels):\n",
    "        self.img_paths = path_to_data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img= np.array(Image.open(self.img_paths[idx]).resize((224, 224), Image.BILINEAR))\n",
    "        im = (img - np.min(img) / (np.max(img) - np.min(img)))\n",
    "        im = np.transpose(im, (2, 1, 0))\n",
    "        \n",
    "        label = np.array(self.labels[idx])\n",
    "        \n",
    "        return {'im' : im, 'label' : label}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random as rd\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import objax\n",
    "from objax.zoo.resnet_v2 import ResNet18, ResNet34\n",
    "import glob\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJAXDataset(Dataset):\n",
    "    def __init__(self, path_to_data, labels, transform = None):\n",
    "        self.img_paths = path_to_data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            im = self.transform(Image.open(self.img_paths[idx]).resize((224, 224), Image.BILINEAR))\n",
    "        \n",
    "        label = np.array(self.labels[idx])\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])     \n",
    "\n",
    "\n",
    "paths = glob.glob('./images/*/*.jpg')\n",
    "image_paths = rd.sample(paths, len(paths))\n",
    "\n",
    "train_image_paths, test_image_paths = image_paths[0:110], image_paths[110:141]\n",
    "train_labels, test_labels =  [int(i.split('/')[2]) for i in train_image_paths], [int(i.split('/')[2]) for i in test_image_paths]\n",
    "\n",
    "\n",
    "train_ds = CustomJAXDataset(train_image_paths, train_labels, transform = transform)\n",
    "test_ds = CustomJAXDataset(test_image_paths, test_labels, transform = transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=10)\n",
    "test_dl = DataLoader(test_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet18(in_channels = 3, num_classes = 3)\n",
    "\n",
    "def conv_relu_pool(in_layers, out_layers, pool=True):\n",
    "    ops = [objax.nn.Conv2D(in_layers, out_layers, 5),\n",
    "            objax.functional.relu]\n",
    "    if pool:\n",
    "        ops.append(lambda x: objax.functional.average_pool_2d(x, size=2, strides=1))\n",
    "    return ops\n",
    "\n",
    "model = objax.nn.Sequential(conv_relu_pool(3, 32) + \\\n",
    "                            conv_relu_pool(32, 32) + \\\n",
    "                            conv_relu_pool(32, 64) + \n",
    "                            conv_relu_pool(64, 64) + \\\n",
    "                            \n",
    "                            [objax.nn.Conv2D(64, 3, 3),\n",
    "                             lambda x: x.mean((2,3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL PARAMS\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \n",
    "    #Optimizer\n",
    "    \n",
    "    opt = objax.optimizer.Adam(model.vars())\n",
    "    \n",
    "    def loss(x, labels):\n",
    "        prediction = model(x, training=True)\n",
    "        \n",
    "        return objax.functional.loss.cross_entropy_logits_sparse(prediction, labels).mean()\n",
    "    \n",
    "    gv = objax.GradValues(loss, model.vars())\n",
    "    \n",
    "    def train_op(x, y, lr):\n",
    "        \n",
    "        g, v = gv(x, y)\n",
    "        opt(lr = lr, grads = g)\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    train_op = objax.Jit(train_op, gv.vars() + opt.vars())\n",
    "    \n",
    "    eval_op = objax.Jit(lambda x: objax.functional.softmax(model(x, training=False)), model.vars())\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for img, label in train_dl:\n",
    "            loss = train_op(x = img.numpy(), y = label.numpy(), lr=0.1)[0]\n",
    "    \n",
    "        accuracy = 0\n",
    "        for img, label in test_dl:\n",
    "            correct_preds = (np.argmax(eval_op(img.numpy()), axis=1) == label.numpy()).sum()\n",
    "            accuracy = correct_preds / len(test_dl)\n",
    "\n",
    "        print('Epoch %04d  Loss %.2f  Accuracy %.2f' % (epoch + 1, loss, 100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pt_36': conda)",
   "language": "python",
   "name": "python361064bitpt36condae3e1a72d28c3471788eb7ee1d404ab9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
