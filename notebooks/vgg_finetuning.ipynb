{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import math\n",
    "import random as rd\n",
    "rd.seed(123)\n",
    "\n",
    "import objax\n",
    "from objax.zoo.vgg import VGG19\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJAXDataset(Dataset):\n",
    "    def __init__(self, path_to_data, labels, transform = None):\n",
    "        \n",
    "        self.img_paths = path_to_data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        im = Image.open(self.img_paths[idx])\n",
    "        if self.transform is not None:\n",
    "            im = self.transform(im)\n",
    "            \n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means =  [0.485, 0.456, 0.406]\n",
    "stds  =  [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224), Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)])     \n",
    "\n",
    "paths = glob.glob('./images/train/*/*.jpg')\n",
    "image_paths = rd.sample(paths, len(paths))\n",
    "\n",
    "train_image_paths, test_image_paths = image_paths[0:110], image_paths[110:141]\n",
    "train_labels, test_labels =  [int(i.split('/')[3]) for i in train_image_paths], [int(i.split('/')[3]) for i in test_image_paths]\n",
    "\n",
    "\n",
    "train_ds = CustomJAXDataset(train_image_paths, train_labels, transform = transform)\n",
    "test_ds = CustomJAXDataset(test_image_paths, test_labels, transform = transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=10)\n",
    "test_dl = DataLoader(test_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(pretrained=True)\n",
    "\n",
    "model_vars = model.vars()\n",
    "\n",
    "new_layer = objax.nn.Linear(4096, 102)\n",
    "\n",
    "new_model = model[:-1]\n",
    "new_model = objax.nn.Sequential(new_model + [new_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #opt = objax.optimizer.Momentum(.vars())\n",
    "    def loss(x, labels):\n",
    "        prediction = model(x, training=True)\n",
    "        \n",
    "        return objax.functional.loss.cross_entropy_logits_sparse(prediction, labels).mean()\n",
    "    \n",
    "    vars_train = objax.VarCollection((k, v) for k, v in new_model.vars().items() if '(Sequential)[42](Linear)' in k)\n",
    "    opt = objax.optimizer.Adam(vars_train)\n",
    "    gv = objax.GradValues(loss, vars_train)\n",
    "    \n",
    "    def train_op(x, y, lr):\n",
    "        \n",
    "        g, v = gv(x, y)\n",
    "        opt(lr = lr, grads = g)\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    train_op = objax.Jit(train_op, gv.vars() + opt.vars())\n",
    "    \n",
    "    eval_op = objax.Jit(lambda x: objax.functional.softmax(model(x, training=False)), model.vars())\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(20):\n",
    "        for img, label in tqdm(train_dl):\n",
    "            loss = train_op(x = img.numpy(), y = label.numpy(), lr = lr)[0]\n",
    "            print('Epoch %04d  Loss %.2f' % (epoch + 1, loss))\n",
    "        accuracy = 0\n",
    "        correct_preds = 0\n",
    "        for img, label in tqdm(test_dl):\n",
    "            correct_preds += (jnp.argmax(eval_op(img.numpy()), axis=1) == label.numpy()).sum()\n",
    "            accuracy = correct_preds / len(test_dl)\n",
    "\n",
    "        \n",
    "        print('Epoch %04d  Loss %.2f  Accuracy %.2f' % (epoch + 1, loss, 100 * accuracy))\n",
    "        #print('Epoch %04d  Loss %.2f' % (epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pt_36': conda)",
   "language": "python",
   "name": "python361064bitpt36condae3e1a72d28c3471788eb7ee1d404ab9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
